{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ-LuE5W-cuV"
   },
   "source": [
    "# Tensorboard Introduction\n",
    "\n",
    "Welcome to the introduction of [`TensorBoard`](https://www.tensorflow.org/tensorboard). In this tutorial, weâ€™ll learn how to:\n",
    "\n",
    "1. Set up TensorBoard\n",
    "2. Write values to TensorBoard\n",
    "3. Inspect a model architecture using TensorBoard\n",
    "4. Train model and write loss, accuracy and some images to TensorBoard\n",
    "\n",
    "Finally we will visualize the effect of different weight initializations on the neural network using `TensorBoard`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGk-OJDG-cuZ"
   },
   "source": [
    "# 1. Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZF0l0DOD-cuZ"
   },
   "source": [
    "TensorBoard helps us track our metrics such as loss, accuracy and visualize the results, model graphs that may be needed during the machine learning workflow. \n",
    "\n",
    "Let's start by installing `TensorBoard`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hVJ6QlBF-cua"
   },
   "outputs": [],
   "source": [
    "# remove the \"> /dev/null\" if you want to see the output of installation status\n",
    "#!pip install tensorboard==2.4 > /dev/null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ugHlrtaq-cub"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorboard version: 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorboard\n",
    "print(f\"Tensorboard version: {tensorboard.__version__}\")\n",
    "if not tensorboard.__version__.startswith(\"2.4\"):\n",
    "    print(\"You are using an another version of Tensorboard. We expect PyTorch 2.4 You may continue using your version but it\"\n",
    "          \" might cause dependency and compatibility issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fY4D6k7f-cub"
   },
   "source": [
    "This tutorial is highly aligned with the `TensorBoard` tutorial from [`PyTorch`](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html). Have a look at that tutorial as well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RMPzSp3e-cuc"
   },
   "source": [
    "## 2. Setting up  TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSqTswN6-cuc"
   },
   "source": [
    "Let's start from where we ended the previous notebook on `PyTorch`. We will again use the [`Fashion-MNIST`](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/) dataset for this notebook.\n",
    "\n",
    "The below cell of code sets up the dataloader and a plotting function to visualize samples from the dataset. This step is very similar to our previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "d_xj2Tmw-cud"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7297ca97d8dd4671917bfd2858b6839d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'FloatProgress' object has no attribute 'style'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-641bafeb0b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                                       \u001b[0;31m# therefore we should add a comma after the values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m fashion_mnist_dataset = torchvision.datasets.FashionMNIST(root='../datasets', train=True,\n\u001b[0m\u001b[1;32m     22\u001b[0m                                                           download=True, transform=transform)\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading {url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m                     \u001b[0mdownload_and_extract_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Failed to download (trying next):\\n{error}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_and_extract_archive\u001b[0;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m     \u001b[0mdownload_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36mdownload_url\u001b[0;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" to \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0m_urlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"https\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/utils.py\u001b[0m in \u001b[0;36m_urlretrieve\u001b[0;34m(url, filename, chunk_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUSER_AGENT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolour\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolour\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# Print initial bar state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mcolour\u001b[0;34m(self, bar_color)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcolour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbar_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'container'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbar_color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FloatProgress' object has no attribute 'style'"
     ]
    }
   ],
   "source": [
    "# import all the required packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))])  # mean and std have to be sequences (e.g. tuples),\n",
    "                                                                      # therefore we should add a comma after the values\n",
    "\n",
    "fashion_mnist_dataset = torchvision.datasets.FashionMNIST(root='../datasets', train=True,\n",
    "                                                          download=True, transform=transform)\n",
    "\n",
    "fashion_mnist_test_dataset = torchvision.datasets.FashionMNIST(root='../datasets', train=False,\n",
    "                                                          download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(fashion_mnist_dataset, batch_size=8)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(fashion_mnist_test_dataset, batch_size=8)\n",
    "\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n",
    "\n",
    "\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.cpu().mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXhChVj1-cue"
   },
   "source": [
    "Always remember to initialize the `device` variable with CUDA enabled GPU, in case it is available. This makes porting of our code to GPU's easier later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O1j_zWQI-cue"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using the device\",device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TO4xGJb-cuf"
   },
   "source": [
    "Let us now intialize a 2-layer neural network model using the `nn.Module` of PyTorch. The model is then moved to the device specified by the `device` variable. We also complete the definitions of the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztuMXiqI-cuf"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, activation=nn.Sigmoid(),\n",
    "                 input_size=1*28*28, hidden_size=100, classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "\n",
    "        # Here we initialize our activation and set up our two linear layers\n",
    "        self.activation = activation\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size) # flatten\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyG7FKN7-cuf"
   },
   "source": [
    "PyTorch provides support for logging data to TensorBoard using the `SummaryWriter` module.\n",
    "We will now initialize an object of`SummaryWriter` and specify the directory [**runs/introduction**] to store its related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KkK725YY-cug"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/introduction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ13pWNY-cug"
   },
   "source": [
    "# 3. Writing to TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajgxxNS2-cug"
   },
   "source": [
    "Let's write some stuff to TensorBoard, and log into it to see how things go. :)\n",
    "\n",
    "\n",
    "You can open the TensorBoard GUI by running the command from this exercise folder in a Terminal:\n",
    "```tensorboard --logdir=runs```\n",
    "\n",
    "For those using Linux or Mac, you can open a Terminal **in this exercise folder** and run the above command.\n",
    "\n",
    "For those using Windows with Anaconda packages, open an Anaconda Prompt and then run the above command. \n",
    "In case you don't  use Anaconda, use your default method of running python code in cmd.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hOXRqzL-cug"
   },
   "source": [
    "![tensorBoard Terminal](./images/tb_terminal.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGUzmK9L-cug"
   },
   "source": [
    "You must be able to see the URL link (  `http://localhost:6006/` in the image) for accessing the tensorboard interface. Let's navigate to that URL in a browser.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8iaKWLk-cuh"
   },
   "source": [
    "If you are using Google Colab, run the following cell to load the TensorBoard extension within the notebook.\n",
    "You may have to scroll to this block whenever you need to look at the tensorboard interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE75Anxc-cuh"
   },
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2L4X8TWe-cuh"
   },
   "source": [
    "\n",
    "No dashboards are created yet! Let's log some data to our `SummaryWriter` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ui89zKwf-cuh"
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "# show images using our helper function\n",
    "matplotlib_imshow(img_grid)\n",
    "\n",
    "# Write the generated image to tensorboard\n",
    "writer.add_image('four_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOcB1-6X-cui"
   },
   "source": [
    "We can now see the image in our TensorBoard interface.  You might need to hit the refresh button on the top right as TensorBoard will only update in discrete intervals of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOksTHy8-cui"
   },
   "source": [
    "![tensorBoard Interface](./images/imgvis.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkthmfwP-cui"
   },
   "source": [
    "# 4. Visualization Model Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fPCt83X-cui"
   },
   "source": [
    "Let's try to now visualize the architecture of our `net` model in Tensorboard. We can even look at input and output dimensions of your model. It is also a good way to debug as the model grows more and more complex.  \n",
    "\n",
    "Let's visualize the model now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lPxtA9vR-cui"
   },
   "outputs": [],
   "source": [
    "writer.add_graph(net.cpu(), images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVzHE07G-cui"
   },
   "source": [
    "![Model Architecture Visualization](./images/tb_model.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8YTM3oZB-cui"
   },
   "source": [
    "Click the `GRAPHS` section in the top ribbon to access it the architecture. The above image was generated by clicking on our network `Net`.\n",
    "Feel free to explore with the various features of this model's visualization! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PzLQ_2N-cuj"
   },
   "source": [
    "# 5. Training network models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGkermUL-cuj"
   },
   "source": [
    "It's now time to explore the most important use of TensorBoard - for model training.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AeYYTy0z-cuj"
   },
   "source": [
    "We shall define two helper functions here: `images_to_probs` and `plot_classes_preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LyP_F_5-cuj"
   },
   "outputs": [],
   "source": [
    "def images_to_probs(net, images):\n",
    "    '''\n",
    "    Returns the predicted class and probabilites of the image belonging to each of the classes \n",
    "    from the network output\n",
    "    '''\n",
    "    output = net(images)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, preds_tensor = torch.max(output, 1)\n",
    "    preds = np.squeeze(preds_tensor.cpu().numpy())\n",
    "    return preds, [F.softmax(el, dim=0)[i].item() for i, el in zip(preds, output)]\n",
    "\n",
    "\n",
    "def plot_classes_preds(net, images, labels):\n",
    "    '''\n",
    "    Returns a plot using the network, along with images\n",
    "    and labels from a batch, that shows the network's class prediction along\n",
    "    with its probability, alongside the actual label, coloring this\n",
    "    information based on whether the prediction was correct or not.\n",
    "    Uses the \"images_to_probs\" function defined above.\n",
    "    '''\n",
    "    preds, probs = images_to_probs(net, images)\n",
    "    # plot the images in the batch, along with predicted and true labels\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    \n",
    "    for idx in np.arange(4):\n",
    "        ax = fig.add_subplot(4, 1.2, idx+1, xticks=[], yticks=[])\n",
    "        fig.tight_layout()\n",
    "        matplotlib_imshow(images[idx], one_channel=True)\n",
    "        ax.set_title(\"{0}, {1:.1f}%(label: {2})\".format(\n",
    "            classes[preds[idx]],\n",
    "            probs[idx] * 100.0,\n",
    "            classes[labels[idx]]),\n",
    "                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"),loc=\"center\",pad=5,fontsize=\"medium\")\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fT0rEAyS-cuj"
   },
   "source": [
    "We are all set up to train the model! Let's use the same framework we used in the `PyTorch` tutorial notebook.\n",
    "\n",
    "Let's write the average loss and the plot generated from `plot_classes_preds` to TensorBoard every 1000 batches  using the `add_scalar` and `add_figure` functions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A_X6JlF5-cuj"
   },
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "running_loss = 0.0\n",
    "net.to(device)\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    for i, data in enumerate(trainloader, 0):#Iterating through the minibatches of the data\n",
    "\n",
    "        # data is a tuple of (inputs, labels)\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Makes sure that the model and the data are in the same device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Reset the parameter gradients for the current  minibatch iteration \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        \n",
    "        outputs = net(inputs)              # Perform a forward pass on the network with inputs\n",
    "        loss = criterion(outputs, labels)  # calculate the loss with the network predictions and ground Truth\n",
    "        loss.backward()                    # Perform a backward pass to calculate the gradients\n",
    "        optimizer.step()                   # Optimise the network parameters with calculated gradients\n",
    "\n",
    "        # Accumulate the loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 1000 == 999:    # every thousandth mini-batch\n",
    "            print(\"[Epoch %d, Iteration %5d]\" % (epoch+1, i+1))\n",
    "\n",
    "            # log the running loss\n",
    "            writer.add_scalar('Training loss',\n",
    "                            running_loss / 1000,\n",
    "                            epoch * len(trainloader) + i)\n",
    "\n",
    "            # log the plot showing the model's predictions on a  sample of mini-batch using our helper function\n",
    "            \n",
    "            writer.add_figure('Predictions vs Actuals',\n",
    "                            plot_classes_preds(net, inputs, labels),\n",
    "                            i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWM9cfKR-cuk"
   },
   "source": [
    "You will now be able to see the plot of loss under `SCALARS` tab. We can also see the  figure for predicted samples in `IMAGES` tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl5uwtob-cuk"
   },
   "source": [
    "![](./images/tb_results1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTKNEWbG-cuk"
   },
   "source": [
    "![](./images/tb_results3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VONH6LeK-cuk"
   },
   "source": [
    "# 6. Experimenting  weight initialization strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHqzFZzF-cuk"
   },
   "source": [
    "We will now  apply all the techniques we have learned in `TensorBoard` to explore the effect of different weight initializations. In the previous exercises, we used a naive Gaussian initialization, though in the lectures you learned that one needs to be careful about the weight initialization values. In addition, weight initialization is dependent on the activation function used.  \n",
    "\n",
    "Let's replicate those experiments!\n",
    "\n",
    "The code below initializes a new `SummaryWriter` instance to log experiment values in the directory `weight_init_experiments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3se88VMb-cuk"
   },
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/weight_init_experiments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqsbP4dE-cuk"
   },
   "source": [
    "Let's define a test network for the experiment and keep track of the output of each layer to find how the input data is modified through the layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DJRFalJz-cul"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, activation_method):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.x1 = torch.Tensor([])\n",
    "        self.x2 = torch.Tensor([])\n",
    "        self.x3 = torch.Tensor([])\n",
    "        self.x4 = torch.Tensor([])\n",
    "        self.x5 = torch.Tensor([])\n",
    "        self.x6 = torch.Tensor([])\n",
    "                \n",
    "        self.fc1 = nn.Linear(28*28, 300)\n",
    "        self.fc2 = nn.Linear(300, 300)\n",
    "        self.fc3 = nn.Linear(300, 300)\n",
    "        self.fc4 = nn.Linear(300, 300)\n",
    "        self.fc5 = nn.Linear(300, 300)\n",
    "        self.fc6 = nn.Linear(300, 300)\n",
    "        self.fc7 = nn.Linear(300, 10)\n",
    "        \n",
    "        if activation_method == \"relu\" :\n",
    "            self.activation = nn.ReLU() \n",
    "        elif activation_method == \"tanh\":\n",
    "            self.activation = nn.Tanh() \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,28*28)\n",
    "        self.x1 = self.activation(self.fc1(x))\n",
    "        self.x2 = self.activation(self.fc2(self.x1))\n",
    "        self.x3 = self.activation(self.fc3(self.x2))\n",
    "        self.x4 = self.activation(self.fc4(self.x3))\n",
    "        self.x5 = self.activation(self.fc5(self.x4))\n",
    "        self.x6 = self.activation(self.fc6(self.x5))\n",
    "        logits = self.fc7 (self.x6)\n",
    "        return logits\n",
    "\n",
    "    def collect_layer_out (self):# Return the output values for each of the network layers\n",
    "        return [self.x1, self.x2, self.x3, self.x4, self.x5, self.x6]\n",
    " \n",
    "net = Net(\"tanh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muJhmlE2-cul"
   },
   "source": [
    "Let's now sample a batch of images for input to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrkuyMxQ-cul"
   },
   "outputs": [],
   "source": [
    "visloader = torch.utils.data.DataLoader(fashion_mnist_dataset, batch_size=40, shuffle=True)\n",
    "dataiter = iter(visloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(\"Size of the Mini-batch input:\",images.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vn5j4A_C-cul"
   },
   "source": [
    "We will plot the histogram of activation values  produced in each of the network layers as the input passes through the network model using the `add_histogram` function. This helps us look at the distribution of activation values. Select the `HISTOGRAMS` tab in TensorBoard to visualise the experiment results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fDAxz5aL-cul"
   },
   "source": [
    "Run the below code block only if you are using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXduIpUA-cul"
   },
   "outputs": [],
   "source": [
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baLDzrDt-cum"
   },
   "source": [
    "## 6.1 Constant weight initialization with $tanh$ activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLo6UcqS-cum"
   },
   "source": [
    "Let's start with constant weight initialization. What problems do you observe with the distribution of the output of each layer? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1XZZwNdz-cum"
   },
   "outputs": [],
   "source": [
    "net_const = Net(\"tanh\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.constant_(m.weight,2.0)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "net_const.apply(init_weights)\n",
    "outputs = net_const(images)\n",
    "layer_out = net_const.collect_layer_out()\n",
    "\n",
    "for i, x in enumerate(layer_out):\n",
    "    writer.add_histogram('constant_init', x, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ujBHxXCF-cum"
   },
   "source": [
    "We can see that initialization with constant values does not break the symmetry of weights, i.e. all neurons in network always learn the same features from the input since the weights are the same.  \n",
    "\n",
    "Now we will try random weight initialization and let's see what happens if weights are initialized with high numerical values or very low numerical values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PRO6LYvG-cum"
   },
   "source": [
    "## 6.2 Random weight initialization of small numerical values with $tanh$ activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BY4RS_yR-cum"
   },
   "outputs": [],
   "source": [
    "net_small_normal = Net(\"tanh\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight,mean=0.0, std=0.01)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "net_small_normal.apply(init_weights)\n",
    "outputs = net_small_normal(images)\n",
    "layer_out = net_small_normal.collect_layer_out()\n",
    "\n",
    "for i, x in enumerate(layer_out):\n",
    "    writer.add_histogram('small_normal_tanh', x, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GOvfzJaR-cum"
   },
   "source": [
    "## 6.3  Random weight initialization of large numerical values with $tanh$ activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYgK-30i-cum"
   },
   "outputs": [],
   "source": [
    "net_large_normal = Net(\"tanh\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.normal_(m.weight,mean=0.0, std=0.2)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "net_large_normal.apply(init_weights)\n",
    "outputs = net_large_normal(images)\n",
    "layer_out = net_large_normal.collect_layer_out()\n",
    "\n",
    "for i, x in enumerate(layer_out):\n",
    "    writer.add_histogram('large_normal_tanh', x, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW8Rnx6D-cun"
   },
   "source": [
    "From last two examples, we can see that random weight initialization with normal distribution might work well in some shallow layers of the network, while if we are going deeper into the network, it will end up with **vanishing gradient problem**, i.e.\n",
    "\n",
    "- If weights are initialized with very high values, the term $Xw+b$ becomes significantly higher and with activation function such as $tanh$, the function returns value very close to $-1$ or $1$. At these values, the gradient of $tanh$ is very low, thus learning takes a lot of time.\n",
    "\n",
    "- If weights are initialized with low values, it gets mapped to around 0, and the small values will kill gradients when backpropagating through the network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DUCTlK1-cun"
   },
   "source": [
    "## 6.4 Xavier initialization with $tanh$ activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Aau8AIt-cun"
   },
   "source": [
    "From the previous examples, we can see that a proper weight initialization is needed to ensure nice distribution of the output of each layers. Here comes the **Xavier Initialization**.\n",
    "\n",
    "We will fill the weight with values using a normal distribution $\\mathcal{N}(0,{\\sigma}^2)$ where\n",
    "\n",
    "$$ \\sigma = gain \\times \\sqrt{\\frac{2}{fan _{in} + fan_{out}}} $$\n",
    "\n",
    "Here $fan _{in}$ and $ fan_{out} $ are number of neurons in the input and output layer and ${gain}$ is a optional scaling factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-zt2SGU-cun"
   },
   "outputs": [],
   "source": [
    "net_xavier = Net(\"tanh\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "net_xavier.apply(init_weights)\n",
    "outputs = net_xavier(images)\n",
    "layer_out = net_xavier.collect_layer_out()\n",
    "\n",
    "for i, x in enumerate(layer_out):\n",
    "    writer.add_histogram('xavier_tanh', x, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhD6xxKt-cun"
   },
   "source": [
    "## 6.5 Xavier initialization with ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBbDKygI-cun"
   },
   "source": [
    "Xavier initialization requires a zero centered activation function such as $tanh$ to work well. Let's try using the Xavier initialization with ReLU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fs2dn_PV-cun"
   },
   "outputs": [],
   "source": [
    "net_xavier_relu = Net(\"relu\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "net_xavier_relu.apply(init_weights)\n",
    "outputs = net_xavier_relu(images)\n",
    "layer_out = net_xavier_relu.collect_layer_out()\n",
    "\n",
    "for i, x in enumerate(layer_out):\n",
    "    writer.add_histogram('xavier_relu', x, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYXYIkJ2-cuo"
   },
   "source": [
    "We can see here that layer outputs collapse to zero again if we use non-zero centered activation such as ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG6UzRB_-cuo"
   },
   "source": [
    "## 6.6 He initialization with ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukopHrz7-cuo"
   },
   "source": [
    "**He Initialization** comes to our rescue for non-centered activation functions. We will fill the weight with values using a normal distribution $\\mathcal{N}(0,\\sigma^2)$ where\n",
    "\n",
    "$$ \\sigma = \\frac {gain} {\\sqrt{fan_{mode}}} $$\n",
    "\n",
    "Here $fan _{mode}$ can be chosen either $fan _{in}$ (default) or $fan _{out}$.\n",
    "\n",
    "Choosing $fan _{in}$ preserves the magnitude of the variance of the weights in the forward pass. Choosing $fan _{out}$ preserves the magnitudes of weights during the backwards pass. The variable $gain$ is again the optional scaling factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbaXIcSd-cuo"
   },
   "outputs": [],
   "source": [
    "net_kaiming_relu = Net(\"relu\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_uniform_(m.weight,nonlinearity='relu')\n",
    "        m.bias.data.fill_(0.01)\n",
    "        \n",
    "net_kaiming_relu.apply(init_weights)\n",
    "outputs = net_kaiming_relu(images)\n",
    "layer_out = net_kaiming_relu.collect_layer_out()\n",
    "\n",
    "for i, x in enumerate(layer_out):\n",
    "    writer.add_histogram('kaiming_relu', x, i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5SsyQmx-cuo"
   },
   "source": [
    "With these, you should have everything at hand to work with Tensorboard. It is highly advised to use either Tensorboard or other similar libraries, such as visdom to visualise network training results.\n",
    "\n",
    "\n",
    "We will now move to the final notebook on [`PyTorchLightning`](https://www.pytorchlightning.ai/), a wrapper for `PyTorch` which makes training neural networks more swifter and easier.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "baLDzrDt-cum",
    "PRO6LYvG-cum",
    "GOvfzJaR-cum",
    "2DUCTlK1-cun",
    "RhD6xxKt-cun",
    "JG6UzRB_-cuo"
   ],
   "name": "2.tensorboard.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
